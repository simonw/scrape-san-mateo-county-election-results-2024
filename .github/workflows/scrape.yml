name: Scrape

on:
  push:
  workflow_dispatch:
  schedule:
  - cron:  '3,23,43 * * * *'

permissions:
  contents: write

jobs:
  fetch:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Set up Python 3.12
      uses: actions/setup-python@v5
      with:
        python-version: "3.12"
        cache: "pip"
    - name: Cache Playwright browsers
      uses: actions/cache@v4
      with:
        path: ~/.cache/ms-playwright/
        key: ${{ runner.os }}-browsers
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    - name: Install Playwright dependencies
      run: |
        shot-scraper install
    - name: Scrape smcacre.gov CSV
      run: |
        url=$(shot-scraper javascript -r \
          "https://smcacre.gov/elections/november-5-2024-election-results" \
          "Array.from(document.querySelectorAll('a')).filter(a => a.innerText.includes('Results on CSV'))[0].href")
        echo "Found URL: $url"
        curl -L -o results.csv "$url"
    - name: Commit and push
      run: |-
        git config user.name "Automated"
        git config user.email "actions@users.noreply.github.com"
        git add -A
        timestamp=$(date -u)
        git commit -m "${timestamp}" || exit 0
        git pull --rebase
        git push
